{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "HRQhCasBht1D",
        "q5Z-i1YfbY32",
        "pZIXjFpodROm",
        "sc7SCOw3i7zd",
        "rHlGxuYmkPE4",
        "EI5z_uPeKNpp",
        "fFZPhXX1bbbe",
        "QyDtiUcoiOmV"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Setup - Don't read - just run"
      ],
      "metadata": {
        "id": "HRQhCasBht1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install --upgrade datasets"
      ],
      "metadata": {
        "id": "FmOv-HoJkQ7I",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ObY3ZGpjZ-tD"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "from openai import OpenAI\n",
        "import random\n",
        "from typing import List, Tuple\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import time\n",
        "import re\n",
        "from getpass import getpass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "LABEL_RE = re.compile(r'\"label\"\\s*:\\s*\"([^\"]+)\"', re.I)\n",
        "\n",
        "def extract_label(raw: str) -> str:\n",
        "    \"\"\"\n",
        "    Find the first occurrence of \"label\": \"â€¦\".\n",
        "    Works even if the JSON block has minor syntax issues\n",
        "    (e.g. trailing commas, single quotes, extra keys).\n",
        "    \"\"\"\n",
        "    m = LABEL_RE.search(raw)\n",
        "    if not m:\n",
        "        return 'oos'\n",
        "    return m.group(1).strip().lower()\n",
        "\n",
        "def get_clinc_test_subset(k: int,\n",
        "                          n_per_class: int,\n",
        "                          seed: int = 42):\n",
        "    ds_test = load_dataset(\"clinc_oos\", \"plus\", split=\"test\")\n",
        "    all_labels = ds_test.features[\"intent\"].names\n",
        "\n",
        "    rng = random.Random(seed)\n",
        "    selected_labels = [\"oos\"] + rng.sample(\n",
        "        [lbl for lbl in all_labels if lbl != \"oos\"], k - 1\n",
        "    )\n",
        "    label2id = {lbl: i for i, lbl in enumerate(all_labels)}\n",
        "\n",
        "    per_class_slices = []\n",
        "    for lbl in selected_labels:\n",
        "        cls_ds = ds_test.filter(lambda ex, lid=label2id[lbl]: ex[\"intent\"] == lid)\n",
        "        take = min(n_per_class, len(cls_ds))\n",
        "        per_class_slices.append(\n",
        "            cls_ds.shuffle(seed=seed).select(range(take))  # <- stays a Dataset\n",
        "        )\n",
        "\n",
        "    balanced_subset = concatenate_datasets(per_class_slices).shuffle(seed=seed)\n",
        "\n",
        "    return {\"intents\": selected_labels, \"test\": balanced_subset}"
      ],
      "metadata": {
        "id": "YklYDXz5HS1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM Clients\n",
        "Please setup your LLM API Key."
      ],
      "metadata": {
        "id": "q5Z-i1YfbY32"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LLM_API_KEY = getpass(\"Please go to aibrary.dev - sign up, get your key and paste it here \")\n",
        "LLM_URL = \"https://api.aibrary.dev/v0\"\n",
        "MODEL_ID = \"Meta-Llama-3.1-8B-Instruct-Turbo\"\n",
        "\n",
        "# OR\n",
        "\n",
        "# LLM_API_KEY = getpass(\"Please go to together.ai - sign up, get your key and paste it here \")\n",
        "# LLM_URL = \"https://api.together.xyz/v1\"\n",
        "# MODEL_ID = \"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo\""
      ],
      "metadata": {
        "id": "R2PniWAFkJq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LLMClient:\n",
        "    def __init__(self, api_key: str, model_name: str, base_url: str, temperature: float = 0.0):\n",
        "        self.client = OpenAI(api_key=api_key, base_url=base_url)\n",
        "        self.model_name = model_name\n",
        "        self.temperature = temperature\n",
        "\n",
        "    def call(self, user_prompt: str, system_prompt: str = '') -> str:\n",
        "        resp = self.client.chat.completions.create(\n",
        "            model=self.model_name,\n",
        "            temperature=self.temperature,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": user_prompt},\n",
        "            ],\n",
        "        )\n",
        "        time.sleep(random.random())\n",
        "        return resp.choices[0].message.content"
      ],
      "metadata": {
        "id": "u8LS3qynaD3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_client = LLMClient(api_key=LLM_API_KEY, model_name=MODEL_ID, base_url=LLM_URL)"
      ],
      "metadata": {
        "id": "qexecCZAaEDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_client.call('are you available?')"
      ],
      "metadata": {
        "id": "SDa2wBnMcNkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "pZIXjFpodROm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "intents_dataset = get_clinc_test_subset(10, 10) # gets 10 classes, 10 samples per class\n",
        "intent_ds = intents_dataset['test']\n",
        "intents = intents_dataset['intents']\n"
      ],
      "metadata": {
        "id": "3a1_ZHxXgkew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,16, 5):\n",
        "    example = intent_ds[i]\n",
        "    print(f\"Text: {example['text']}\")\n",
        "    print(f\"Label: {intent_ds.features['intent'].names[example['intent']]}\")\n",
        "    print(\"---\")"
      ],
      "metadata": {
        "id": "OpypKEeLi1bK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intents"
      ],
      "metadata": {
        "id": "qQju5TXNh0gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM for Intent Classification"
      ],
      "metadata": {
        "id": "sc7SCOw3i7zd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_system_prompt(intents: List[str]) -> str:\n",
        "    \"\"\"Return a short system instruction listing all valid intents.\"\"\"\n",
        "    return (\n",
        "        \"You are an intent classifier for a voice assistant. \"\n",
        "        \"Return exactly one intent label from the list below. \"\n",
        "        \"If the user request does not match any intent, return 'oos'.\\n\\n\"\n",
        "        + \", \".join(intents)\n",
        "    )\n",
        "system_prompt = build_system_prompt(intents)\n",
        "print(system_prompt)"
      ],
      "metadata": {
        "id": "t5JettvMh-1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_prompt = \"\"\"\n",
        "User: i think i've misplaced my phone\n",
        "\"\"\"\n",
        "llm_client.call(user_prompt, system_prompt)"
      ],
      "metadata": {
        "id": "kV0yybmyooX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_user_prompt(utterance) -> str:\n",
        "  return f\"User: {utterance}\\n\"\n",
        "\n",
        "user_prompt = build_user_prompt(\"where did i place my phone\")\n",
        "print(user_prompt)"
      ],
      "metadata": {
        "id": "VtOrR6Pwj6tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_client.call(user_prompt, system_prompt)"
      ],
      "metadata": {
        "id": "7wycnlltp6cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InferenceRunner:\n",
        "    def __init__(self, llm_client, build_system_prompt, build_user_prompt):\n",
        "        self.llm_client = llm_client\n",
        "        self.build_system_prompt = build_system_prompt\n",
        "        self.build_user_prompt = build_user_prompt\n",
        "\n",
        "    def run(self, dataset_split, intents):\n",
        "        sys_prompt = self.build_system_prompt(intents)\n",
        "        results = []\n",
        "        for ex in tqdm(dataset_split, desc=\"inference\"):\n",
        "            user_prompt = self.build_user_prompt(ex[\"text\"])\n",
        "            pred = self.llm_client.call(user_prompt, sys_prompt).strip().lower()\n",
        "            results.append({\n",
        "                \"text\": ex[\"text\"],\n",
        "                \"pred\": pred,\n",
        "            })\n",
        "        return results"
      ],
      "metadata": {
        "id": "YROiFeyRvKiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inf_runner = InferenceRunner(llm_client, build_system_prompt, build_user_prompt)\n",
        "results = inf_runner.run(intent_ds, intents)"
      ],
      "metadata": {
        "id": "SqTTcYNAvnqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "rHlGxuYmkPE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_dataframe(predictions, dataset_split, intents):\n",
        "    records = []\n",
        "    for pred_obj, gt in zip(predictions, dataset_split):\n",
        "        records.append({\n",
        "            \"text\": pred_obj[\"text\"],\n",
        "            \"pred\": pred_obj[\"pred\"],\n",
        "            \"label\": dataset_split.features['intent'].names[gt[\"intent\"]],\n",
        "        })\n",
        "    return pd.DataFrame(records)\n",
        "\n",
        "df = to_dataframe(results, intent_ds, intents)\n",
        "accuracy = (df[\"pred\"] == df[\"label\"]).mean()\n",
        "print(\"Accuracy:\", 100*accuracy, \"%\")"
      ],
      "metadata": {
        "id": "c7KOcnL1kBCr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Error Analysis"
      ],
      "metadata": {
        "id": "EI5z_uPeKNpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "error_df = df[df.label != df.pred]"
      ],
      "metadata": {
        "id": "5L6vltbyKM9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for _, row in error_df.iterrows():\n",
        "  print('Query:', row['text'])\n",
        "  print('Expected:', row['label'], 'Predicted:', row['pred'])\n",
        "  print('----')"
      ],
      "metadata": {
        "id": "6TzSoTYgGdiP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_system_prompt_cot(intents):\n",
        "    \"\"\"\n",
        "    Model thinks first, then prints one clean JSON line.\n",
        "    \"\"\"\n",
        "    return (\n",
        "        \"You are an intent classifier for a voice assistant.\\n\"\n",
        "        \"Think step-by-step first.\\n\"\n",
        "        \"Then, on a new line, output **exactly** this one-line JSON:\\n\"\n",
        "        '{\"label\": \"<one of these intents or \\'oos\\'>\"}\\n'\n",
        "        \"No markdown, no extra keys, no trailing commas.\\n\\n\"\n",
        "        \"Valid intents: \" + \", \".join(intents)\n",
        "    )\n",
        "\n",
        "inf_runner = InferenceRunner(llm_client, build_system_prompt_cot, build_user_prompt)\n",
        "results = inf_runner.run(intent_ds, intents)"
      ],
      "metadata": {
        "id": "M9tuCrZMK1Sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = to_dataframe(results, intent_ds, intents)\n",
        "df['pred_label'] = df['pred'].apply(extract_label)\n",
        "accuracy = (df[\"pred_label\"] == df[\"label\"]).mean()\n",
        "print(\"Accuracy:\", 100*accuracy, \"%\")"
      ],
      "metadata": {
        "id": "l-433aumR3Zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error_df = df[df.label != df.pred_label]\n",
        "for _, row in error_df.iterrows():\n",
        "  print('Query:', row['text'])\n",
        "  print('Expected:', row['label'])\n",
        "  print('Predicted:', row['pred'])\n",
        "  print('----')"
      ],
      "metadata": {
        "id": "wCGhuQ0tSDjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Self-consistency"
      ],
      "metadata": {
        "id": "fFZPhXX1bbbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def majority_vote_label(client, utter: str, sys: str, m: int = 3) -> str:\n",
        "    from collections import Counter\n",
        "    labels = [\n",
        "        extract_label(client.call(build_user_prompt(utter), sys))\n",
        "        for _ in range(m)\n",
        "    ]\n",
        "    return Counter(labels).most_common(1)[0][0]\n"
      ],
      "metadata": {
        "id": "ahDT21S1e4BC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_temp = LLMClient(\n",
        "    api_key=LLM_API_KEY,\n",
        "    model_name=MODEL_ID,\n",
        "    base_url=LLM_URL,\n",
        "    temperature=0.8          # diversity is essential for voting\n",
        ")\n",
        "sys_prompt = build_system_prompt(intents)   # or build_system_prompt_cot"
      ],
      "metadata": {
        "id": "XS-RrrR4e9Un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error_df = error_df.copy()\n",
        "error_df[\"pred_mv\"] = error_df[\"text\"].apply(\n",
        "    lambda t: majority_vote_label(llm_temp, t, sys_prompt, m=3)\n",
        ")"
      ],
      "metadata": {
        "id": "NEbi4tJ0bkYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fixed = (error_df.pred_mv == error_df.label).sum()\n",
        "print(f\"Self-consistency corrected {fixed}/{len(error_df)} errors \"\n",
        "      f\"({fixed/len(error_df)*100:.1f} %).\")"
      ],
      "metadata": {
        "id": "L1aeUDm1S4b5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Activity - Trim the Thoughts, Keep the Smarts\n",
        "\n",
        "### Chain of Thought is taking x times longer\n",
        "Your task is to reduce the inference time by guiding the model to reason only briefly and then output the decision to reduce latency and token usage."
      ],
      "metadata": {
        "id": "QyDtiUcoiOmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# todo"
      ],
      "metadata": {
        "id": "DVoJvq5oiP9k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}